{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93f3c974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "import gensim\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65d84a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('AI trainining data.xlsx - data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a4c05ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>twitterHandlerused</th>\n",
       "      <th>label</th>\n",
       "      <th>fasttext_labels</th>\n",
       "      <th>Comparison_human&amp;ft</th>\n",
       "      <th>Labels_Manish_Krishna_Anu_Harvinder</th>\n",
       "      <th>2nd review</th>\n",
       "      <th>Final_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@HatePatroller All @mindvalley students are li...</td>\n",
       "      <td>@mindvalley</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @AlphaGammaHQ: Conferences are great platfo...</td>\n",
       "      <td>@mindvalley</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@AlphaGammaHQ @wobi_en @GIFLondon @Esportsbzsu...</td>\n",
       "      <td>@mindvalley</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @mindvalley: You asked, we delivered. ÃƒÂ°Ã...</td>\n",
       "      <td>@mindvalley</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@dubeji18 Check this one out by @thesleepdocto...</td>\n",
       "      <td>@mindvalley</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet twitterHandlerused  \\\n",
       "0  @HatePatroller All @mindvalley students are li...        @mindvalley   \n",
       "1  RT @AlphaGammaHQ: Conferences are great platfo...        @mindvalley   \n",
       "2  @AlphaGammaHQ @wobi_en @GIFLondon @Esportsbzsu...        @mindvalley   \n",
       "3  RT @mindvalley: You asked, we delivered. ÃƒÂ°Ã...        @mindvalley   \n",
       "4  @dubeji18 Check this one out by @thesleepdocto...        @mindvalley   \n",
       "\n",
       "      label fasttext_labels Comparison_human&ft  \\\n",
       "0   Neutral         Neutral                 NaN   \n",
       "1  Positive        Positive                 NaN   \n",
       "2  Positive        Positive                 NaN   \n",
       "3   Neutral         Neutral                 NaN   \n",
       "4   Neutral         Neutral                 NaN   \n",
       "\n",
       "  Labels_Manish_Krishna_Anu_Harvinder  2nd review Final_labels  \n",
       "0                             Neutral         NaN      Neutral  \n",
       "1                             Neutral         NaN     Positive  \n",
       "2                                 NaN         NaN     Positive  \n",
       "3                                 NaN         NaN      Neutral  \n",
       "4                                 NaN         NaN      Neutral  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a95529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['label' , 'fasttext_labels' , 'Comparison_human&ft' ,\n",
    "                        'Labels_Manish_Krishna_Anu_Harvinder' ,'2nd review' , 'twitterHandlerused' ] , axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15c4df9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutral', 'Positive', 'Negative'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Final_labels'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9393cb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to C:\\Users\\prashant\n",
      "[nltk_data]     pathak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bc0e4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(tweet):\n",
    "    tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) #Remove @ sign\n",
    "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) #Remove http links\n",
    "    tweet = \" \".join(tweet.split())\n",
    "    #tweet = ''.join(c for c in tweet if c not in emoji.UNICODE_EMOJI) #Remove Emojis\n",
    "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \") #Remove hashtag sign but keep the text\n",
    "    tweet = \" \".join(w for w in nltk.wordpunct_tokenize(tweet) \\\n",
    "         if w.lower() in words or not w.isalpha())\n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "074097ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "def text_cleaning(text):\n",
    "    \n",
    "    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n",
    "    text = template.sub(r'', text)\n",
    "    \n",
    "    soup = BeautifulSoup(text,  \"html.parser\") #Removes HTML tags\n",
    "    only_text = soup.get_text()\n",
    "    text = only_text\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n",
    "    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n",
    "    text = text.strip() # remove spaces at the beginning and at the end of string\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f763476",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def clean(data, col):\n",
    "    \n",
    "    data[col] = data[col].str.replace('https?://\\S+|www\\.\\S+', ' social medium ', regex=True)      \n",
    "        \n",
    "    data[col] = data[col].str.lower()\n",
    "    data[col] = data[col].str.replace(\"4\", \"a\") \n",
    "    data[col] = data[col].str.replace(\"2\", \"l\")\n",
    "    data[col] = data[col].str.replace(\"5\", \"s\") \n",
    "    data[col] = data[col].str.replace(\"1\", \"i\") \n",
    "    data[col] = data[col].str.replace(\"!\", \"i\") \n",
    "    data[col] = data[col].str.replace(\"|\", \"i\", regex=False) \n",
    "    data[col] = data[col].str.replace(\"0\", \"o\") \n",
    "    data[col] = data[col].str.replace(\"l3\", \"b\") \n",
    "    data[col] = data[col].str.replace(\"7\", \"t\") \n",
    "    data[col] = data[col].str.replace(\"7\", \"+\") \n",
    "    data[col] = data[col].str.replace(\"8\", \"ate\") \n",
    "    data[col] = data[col].str.replace(\"3\", \"e\") \n",
    "    data[col] = data[col].str.replace(\"9\", \"g\")\n",
    "    data[col] = data[col].str.replace(\"6\", \"g\")\n",
    "    data[col] = data[col].str.replace(\"@\", \"a\")\n",
    "    data[col] = data[col].str.replace(\"$\", \"s\", regex=False)\n",
    "    data[col] = data[col].str.replace(\"#ofc\", \" of fuckin course \")\n",
    "    data[col] = data[col].str.replace(\"fggt\", \" faggot \")\n",
    "    data[col] = data[col].str.replace(\"your\", \" your \")\n",
    "    data[col] = data[col].str.replace(\"self\", \" self \")\n",
    "    data[col] = data[col].str.replace(\"cuntbag\", \" cunt bag \")\n",
    "    data[col] = data[col].str.replace(\"fartchina\", \" fart china \")    \n",
    "    data[col] = data[col].str.replace(\"youi\", \" you i \")\n",
    "    data[col] = data[col].str.replace(\"cunti\", \" cunt i \")\n",
    "    data[col] = data[col].str.replace(\"sucki\", \" suck i \")\n",
    "    data[col] = data[col].str.replace(\"pagedelete\", \" page delete \")\n",
    "    data[col] = data[col].str.replace(\"cuntsi\", \" cuntsi \")\n",
    "    data[col] = data[col].str.replace(\"i'm\", \" i am \")\n",
    "    data[col] = data[col].str.replace(\"offuck\", \" of fuck \")\n",
    "    data[col] = data[col].str.replace(\"centraliststupid\", \" central ist stupid \")\n",
    "    data[col] = data[col].str.replace(\"hitleri\", \" hitler i \")\n",
    "    data[col] = data[col].str.replace(\"i've\", \" i have \")\n",
    "    data[col] = data[col].str.replace(\"i'll\", \" sick \")\n",
    "    data[col] = data[col].str.replace(\"fuck\", \" fuck \")\n",
    "    data[col] = data[col].str.replace(\"f u c k\", \" fuck \")\n",
    "    data[col] = data[col].str.replace(\"shit\", \" shit \")\n",
    "    data[col] = data[col].str.replace(\"bunksteve\", \" bunk steve \")\n",
    "    data[col] = data[col].str.replace('wikipedia', ' social medium ')\n",
    "    data[col] = data[col].str.replace(\"faggot\", \" faggot \")\n",
    "    data[col] = data[col].str.replace(\"delanoy\", \" delanoy \")\n",
    "    data[col] = data[col].str.replace(\"jewish\", \" jewish \")\n",
    "    data[col] = data[col].str.replace(\"sexsex\", \" sex \")\n",
    "    data[col] = data[col].str.replace(\"allii\", \" all ii \")\n",
    "    data[col] = data[col].str.replace(\"i'd\", \" i had \")\n",
    "    data[col] = data[col].str.replace(\"'s\", \" is \")\n",
    "    data[col] = data[col].str.replace(\"youbollocks\", \" you bollocks \")\n",
    "    data[col] = data[col].str.replace(\"dick\", \" dick \")\n",
    "    data[col] = data[col].str.replace(\"cuntsi\", \" cuntsi \")\n",
    "    data[col] = data[col].str.replace(\"mothjer\", \" mother \")\n",
    "    data[col] = data[col].str.replace(\"cuntfranks\", \" cunt \")\n",
    "    data[col] = data[col].str.replace(\"ullmann\", \" jewish \")\n",
    "    data[col] = data[col].str.replace(\"mr.\", \" mister \", regex=False)\n",
    "    data[col] = data[col].str.replace(\"aidsaids\", \" aids \")\n",
    "    data[col] = data[col].str.replace(\"njgw\", \" nigger \")\n",
    "    data[col] = data[col].str.replace(\"wiki\", \" social medium \")\n",
    "    data[col] = data[col].str.replace(\"administrator\", \" admin \")\n",
    "    data[col] = data[col].str.replace(\"gamaliel\", \" jewish \")\n",
    "    data[col] = data[col].str.replace(\"rvv\", \" vanadalism \")\n",
    "    data[col] = data[col].str.replace(\"admins\", \" admin \")\n",
    "    data[col] = data[col].str.replace(\"pensnsnniensnsn\", \" penis \")\n",
    "    data[col] = data[col].str.replace(\"pneis\", \" penis \")\n",
    "    data[col] = data[col].str.replace(\"pennnis\", \" penis \")\n",
    "    data[col] = data[col].str.replace(\"pov.\", \" point of view \", regex=False)\n",
    "    data[col] = data[col].str.replace(\"vandalising\", \" vandalism \")\n",
    "    data[col] = data[col].str.replace(\"cock\", \" dick \")\n",
    "    data[col] = data[col].str.replace(\"asshole\", \" asshole \")\n",
    "    data[col] = data[col].str.replace(\"youi\", \" you \")\n",
    "    data[col] = data[col].str.replace(\"afd\", \" all fucking day \")\n",
    "    data[col] = data[col].str.replace(\"sockpuppets\", \" sockpuppetry \")\n",
    "    data[col] = data[col].str.replace(\"iiprick\", \" iprick \")\n",
    "    data[col] = data[col].str.replace(\"penisi\", \" penis \")\n",
    "    data[col] = data[col].str.replace(\"warrior\", \" warrior \")\n",
    "    data[col] = data[col].str.replace(\"loil\", \" laughing out insanely loud \")\n",
    "    data[col] = data[col].str.replace(\"vandalise\", \" vanadalism \")\n",
    "    data[col] = data[col].str.replace(\"helli\", \" helli \")\n",
    "    data[col] = data[col].str.replace(\"lunchablesi\", \" lunchablesi \")\n",
    "    data[col] = data[col].str.replace(\"special\", \" special \")\n",
    "    data[col] = data[col].str.replace(\"ilol\", \" i lol \")\n",
    "    data[col] = data[col].str.replace(r'\\b[uU]\\b', 'you', regex=True)\n",
    "    data[col] = data[col].str.replace(r\"what's\", \"what is \")\n",
    "    data[col] = data[col].str.replace(r\"\\'s\", \" is \", regex=False)\n",
    "    data[col] = data[col].str.replace(r\"\\'ve\", \" have \", regex=False)\n",
    "    data[col] = data[col].str.replace(r\"can't\", \"cannot \")\n",
    "    data[col] = data[col].str.replace(r\"n't\", \" not \")\n",
    "    data[col] = data[col].str.replace(r\"i'm\", \"i am \")\n",
    "    data[col] = data[col].str.replace(r\"\\'re\", \" are \", regex=False)\n",
    "    data[col] = data[col].str.replace(r\"\\'d\", \" would \", regex=False)\n",
    "    data[col] = data[col].str.replace(r\"\\'ll\", \" will \", regex=False)\n",
    "    data[col] = data[col].str.replace(r\"\\'scuse\", \" excuse \", regex=False)\n",
    "    data[col] = data[col].str.replace('\\s+', ' ', regex=True)  # will remove more than one whitespace character\n",
    "#     text = re.sub(r'\\b([^\\W\\d_]+)(\\s+\\1)+\\b', r'\\1', re.sub(r'\\W+', ' ', text).strip(), flags=re.I)  # remove repeating words coming immediately one after another\n",
    "    data[col] = data[col].str.replace(r'(.)\\1+', r'\\1\\1', regex=True) # 2 or more characters are replaced by 2 characters\n",
    "#     text = re.sub(r'((\\b\\w+\\b.{1,2}\\w+\\b)+).+\\1', r'\\1', text, flags = re.I)\n",
    "    data[col] = data[col].str.replace(\"[:|♣|'|§|♠|*|/|?|=|%|&|-|#|•|~|^|>|<|►|_]\", '', regex=True)\n",
    "    \n",
    "    \n",
    "    data[col] = data[col].str.replace(r\"what's\", \"what is \")    \n",
    "    data[col] = data[col].str.replace(r\"\\'ve\", \" have \", regex=False)\n",
    "    data[col] = data[col].str.replace(r\"can't\", \"cannot \")\n",
    "    data[col] = data[col].str.replace(r\"n't\", \" not \", regex=False)\n",
    "    data[col] = data[col].str.replace(r\"i'm\", \"i am \", regex=False)\n",
    "    data[col] = data[col].str.replace(r\"\\'re\", \" are \", regex=False)\n",
    "    data[col] = data[col].str.replace(r\"\\'d\", \" would \", regex=False)\n",
    "    data[col] = data[col].str.replace(r\"\\'ll\", \" will \", regex=False)\n",
    "    data[col] = data[col].str.replace(r\"\\'scuse\", \" excuse \", regex=False)\n",
    "    data[col] = data[col].str.replace(r\"\\'s\", \" \", regex=False)\n",
    "    data[col] = data[col].str.replace(r\"en\" , \"\" , regex = False)\n",
    "    # Clean some punctutations\n",
    "    data[col] = data[col].str.replace('\\n', ' \\n ')\n",
    "    data[col] = data[col].str.replace(r'([a-zA-Z]+)([/!?.])([a-zA-Z]+)',r'\\1 \\2 \\3', regex=True)\n",
    "    # Replace repeating characters more than 3 times to length of 3\n",
    "    data[col] = data[col].str.replace(r'([*!?\\'])\\1\\1{2,}',r'\\1\\1\\1', regex=True)    \n",
    "    # Add space around repeating characters\n",
    "    data[col] = data[col].str.replace(r'([*!?\\']+)',r' \\1 ', regex=True)    \n",
    "    # patterns with repeating characters \n",
    "    data[col] = data[col].str.replace(r'([a-zA-Z])\\1{2,}\\b',r'\\1\\1', regex=True)\n",
    "    data[col] = data[col].str.replace(r'([a-zA-Z])\\1\\1{2,}\\B',r'\\1\\1\\1', regex=True)\n",
    "    data[col] = data[col].str.replace(r'[ ]{2,}',' ', regex=True).str.strip()   \n",
    "    data[col] = data[col].str.replace(r'[ ]{2,}',' ', regex=True).str.strip()   \n",
    "    data[col] = data[col].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "    tqdm_notebook.pandas()\n",
    "    data[col] = data[col].progress_apply(text_cleaning)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c50da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "365941d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tweet'] = train['tweet'].apply(cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdfe0631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\prashant pathak\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\bs4\\__init__.py:332: MarkupResemblesLocatorWarning: \".\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train['tweet'] = train['tweet'].apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "905a7077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79332b7679ba49e2b76339b518c30fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = clean(train , 'tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3806ea20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Final_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great learn exchange meet like minded people b...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>awesome list humble thank us</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>us make free evt</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>check one highly consideration natural help ma...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet Final_labels\n",
       "0                                               like      Neutral\n",
       "1  great learn exchange meet like minded people b...     Positive\n",
       "2                       awesome list humble thank us     Positive\n",
       "3                                   us make free evt      Neutral\n",
       "4  check one highly consideration natural help ma...      Neutral"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764720a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be088c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(train['Final_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b531eaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4104\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef124256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Final_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great learn exchange meet like minded people b...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet Final_labels\n",
       "0                                               like      Neutral\n",
       "1  great learn exchange meet like minded people b...     Positive"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "712facd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('Final_labels' , axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f18afdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4104"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d83239a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4104, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8d8ad82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 2 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "j = []\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 'Neutral':\n",
    "        j.append(0)\n",
    "    if labels[i] == 'Negative':\n",
    "        j.append(1)\n",
    "    if labels[i] == 'Positive':\n",
    "        j.append(2)\n",
    "j = np.array(j)\n",
    "print(j)\n",
    "labels = tf.keras.utils.to_categorical(j, 3, dtype=\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212ec41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c12438c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0f7a783",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train['tweet'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a359237a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['like'], ['great', 'learn', 'exchange', 'meet', 'like', 'minded', 'people', 'build'], ['awesome', 'list', 'humble', 'thank', 'us'], ['us', 'make', 'free', 'evt'], ['check', 'one', 'highly', 'consideration', 'natural', 'help', 'master', 'sleep'], ['hey', 'come', 'join', 'free', 'summit', 'es', 'share', 'well', 'waiting', 'join'], ['also', 'try', 'tea', 'eo', 'ao', 'going', 'bed', 'amazing', 'see', 'immediate'], ['interesting', 'thanks', 'appreciate'], ['wonderful', 'speaking', 'time', 'rife', 'time', 'redefine'], ['great', 'one', 'mind', 'us', 'eastern', 'knowledge', 'western', 'colonialism', 'much', 'shame', 'mockery', 'eastern', 'west', 'much', 'self', 'rejection']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "        \n",
    "\n",
    "data_words = list(sent_to_words(temp))\n",
    "\n",
    "print(data_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "834f0c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detokenize(text):\n",
    "    return TreebankWordDetokenizer().detokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "026e4350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['like', 'great learn exchange meet like minded people build', 'awesome list humble thank us', 'us make free evt', 'check one highly consideration natural help master sleep']\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in range(len(data_words)):\n",
    "    data.append(detokenize(data_words[i]))\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c8ff528",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7262669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...    0    0   11]\n",
      " [   0    0    0 ... 1236   10  603]\n",
      " [   0    0    0 ... 1469    7   22]\n",
      " ...\n",
      " [   0    0    0 ...   51  601   41]\n",
      " [   0    0    0 ...    0 1849 2282]\n",
      " [   0    0    0 ... 1825  198 1461]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "max_words = 5000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(data)\n",
    "sequences = tokenizer.texts_to_sequences(data)\n",
    "tweets = pad_sequences(sequences, maxlen=max_len)\n",
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3947fcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ba7503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tweets, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb4bc85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c703594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.8928 - accuracy: 0.6442\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67600, saving model to best_model2.hdf5\n",
      "103/103 [==============================] - 11s 37ms/step - loss: 0.8928 - accuracy: 0.6442 - val_loss: 0.7959 - val_accuracy: 0.6760\n",
      "Epoch 2/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.8109 - accuracy: 0.6513\n",
      "Epoch 00002: val_accuracy improved from 0.67600 to 0.67966, saving model to best_model2.hdf5\n",
      "103/103 [==============================] - 2s 24ms/step - loss: 0.8094 - accuracy: 0.6525 - val_loss: 0.7530 - val_accuracy: 0.6797\n",
      "Epoch 3/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7391 - accuracy: 0.6683\n",
      "Epoch 00003: val_accuracy improved from 0.67966 to 0.70280, saving model to best_model2.hdf5\n",
      "103/103 [==============================] - 3s 24ms/step - loss: 0.7391 - accuracy: 0.6683 - val_loss: 0.6746 - val_accuracy: 0.7028\n",
      "Epoch 4/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.6573 - accuracy: 0.7120\n",
      "Epoch 00004: val_accuracy improved from 0.70280 to 0.75152, saving model to best_model2.hdf5\n",
      "103/103 [==============================] - 2s 24ms/step - loss: 0.6563 - accuracy: 0.7118 - val_loss: 0.6160 - val_accuracy: 0.7515\n",
      "Epoch 5/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.5818 - accuracy: 0.7685\n",
      "Epoch 00005: val_accuracy improved from 0.75152 to 0.78928, saving model to best_model2.hdf5\n",
      "103/103 [==============================] - 4s 34ms/step - loss: 0.5818 - accuracy: 0.7685 - val_loss: 0.5506 - val_accuracy: 0.7893\n",
      "Epoch 6/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.5118 - accuracy: 0.8102\n",
      "Epoch 00006: val_accuracy improved from 0.78928 to 0.81486, saving model to best_model2.hdf5\n",
      "103/103 [==============================] - 3s 31ms/step - loss: 0.5118 - accuracy: 0.8102 - val_loss: 0.5086 - val_accuracy: 0.8149\n",
      "Epoch 7/70\n",
      "101/103 [============================>.] - ETA: 0s - loss: 0.4589 - accuracy: 0.8360\n",
      "Epoch 00007: val_accuracy improved from 0.81486 to 0.83191, saving model to best_model2.hdf5\n",
      "103/103 [==============================] - 3s 33ms/step - loss: 0.4568 - accuracy: 0.8364 - val_loss: 0.4919 - val_accuracy: 0.8319\n",
      "Epoch 8/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.4225 - accuracy: 0.8431\n",
      "Epoch 00008: val_accuracy improved from 0.83191 to 0.83678, saving model to best_model2.hdf5\n",
      "103/103 [==============================] - 3s 26ms/step - loss: 0.4225 - accuracy: 0.8431 - val_loss: 0.4764 - val_accuracy: 0.8368\n",
      "Epoch 9/70\n",
      "101/103 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8629\n",
      "Epoch 00009: val_accuracy did not improve from 0.83678\n",
      "103/103 [==============================] - 3s 26ms/step - loss: 0.3883 - accuracy: 0.8623 - val_loss: 0.4774 - val_accuracy: 0.8246\n",
      "Epoch 10/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.3682 - accuracy: 0.8663\n",
      "Epoch 00010: val_accuracy did not improve from 0.83678\n",
      "103/103 [==============================] - 3s 25ms/step - loss: 0.3682 - accuracy: 0.8663 - val_loss: 0.4783 - val_accuracy: 0.8331\n",
      "Epoch 11/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.3515 - accuracy: 0.8759\n",
      "Epoch 00011: val_accuracy did not improve from 0.83678\n",
      "103/103 [==============================] - 3s 26ms/step - loss: 0.3502 - accuracy: 0.8763 - val_loss: 0.4737 - val_accuracy: 0.8283\n",
      "Epoch 12/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.3263 - accuracy: 0.8824\n",
      "Epoch 00012: val_accuracy did not improve from 0.83678\n",
      "103/103 [==============================] - 3s 26ms/step - loss: 0.3273 - accuracy: 0.8821 - val_loss: 0.4744 - val_accuracy: 0.8295\n",
      "Epoch 13/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.3181 - accuracy: 0.8882\n",
      "Epoch 00013: val_accuracy did not improve from 0.83678\n",
      "103/103 [==============================] - 3s 29ms/step - loss: 0.3181 - accuracy: 0.8882 - val_loss: 0.4867 - val_accuracy: 0.8197\n",
      "Epoch 14/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.3143 - accuracy: 0.8876\n",
      "Epoch 00014: val_accuracy improved from 0.83678 to 0.83800, saving model to best_model2.hdf5\n",
      "103/103 [==============================] - 3s 27ms/step - loss: 0.3132 - accuracy: 0.8879 - val_loss: 0.4783 - val_accuracy: 0.8380\n",
      "Epoch 15/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.2894 - accuracy: 0.8958\n",
      "Epoch 00015: val_accuracy did not improve from 0.83800\n",
      "103/103 [==============================] - 3s 27ms/step - loss: 0.2892 - accuracy: 0.8958 - val_loss: 0.4909 - val_accuracy: 0.8331\n",
      "Epoch 16/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.2766 - accuracy: 0.8961\n",
      "Epoch 00016: val_accuracy did not improve from 0.83800\n",
      "103/103 [==============================] - 3s 27ms/step - loss: 0.2782 - accuracy: 0.8955 - val_loss: 0.4917 - val_accuracy: 0.8307\n",
      "Epoch 17/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.2821 - accuracy: 0.9010\n",
      "Epoch 00017: val_accuracy did not improve from 0.83800\n",
      "103/103 [==============================] - 3s 27ms/step - loss: 0.2821 - accuracy: 0.9010 - val_loss: 0.4928 - val_accuracy: 0.8368\n",
      "Epoch 18/70\n",
      "101/103 [============================>.] - ETA: 0s - loss: 0.2703 - accuracy: 0.9032\n",
      "Epoch 00018: val_accuracy did not improve from 0.83800\n",
      "103/103 [==============================] - 3s 27ms/step - loss: 0.2698 - accuracy: 0.9031 - val_loss: 0.5239 - val_accuracy: 0.8343\n",
      "Epoch 19/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.2641 - accuracy: 0.9092\n",
      "Epoch 00019: val_accuracy improved from 0.83800 to 0.84044, saving model to best_model2.hdf5\n",
      "103/103 [==============================] - 3s 28ms/step - loss: 0.2641 - accuracy: 0.9092 - val_loss: 0.5194 - val_accuracy: 0.8404\n",
      "Epoch 20/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.2496 - accuracy: 0.9108\n",
      "Epoch 00020: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 27ms/step - loss: 0.2496 - accuracy: 0.9108 - val_loss: 0.5216 - val_accuracy: 0.8197\n",
      "Epoch 21/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.2455 - accuracy: 0.9095\n",
      "Epoch 00021: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 32ms/step - loss: 0.2455 - accuracy: 0.9095 - val_loss: 0.5126 - val_accuracy: 0.8295\n",
      "Epoch 22/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.2346 - accuracy: 0.9157\n",
      "Epoch 00022: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 32ms/step - loss: 0.2343 - accuracy: 0.9159 - val_loss: 0.5133 - val_accuracy: 0.8343\n",
      "Epoch 23/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.2318 - accuracy: 0.9208\n",
      "Epoch 00023: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 34ms/step - loss: 0.2318 - accuracy: 0.9208 - val_loss: 0.5257 - val_accuracy: 0.8319\n",
      "Epoch 24/70\n",
      "101/103 [============================>.] - ETA: 0s - loss: 0.2372 - accuracy: 0.9192\n",
      "Epoch 00024: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 28ms/step - loss: 0.2367 - accuracy: 0.9196 - val_loss: 0.5181 - val_accuracy: 0.8343\n",
      "Epoch 25/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.2234 - accuracy: 0.9226\n",
      "Epoch 00025: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 29ms/step - loss: 0.2234 - accuracy: 0.9226 - val_loss: 0.5255 - val_accuracy: 0.8404\n",
      "Epoch 26/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.2147 - accuracy: 0.9232\n",
      "Epoch 00026: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 28ms/step - loss: 0.2147 - accuracy: 0.9232 - val_loss: 0.5291 - val_accuracy: 0.8283\n",
      "Epoch 27/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.2129 - accuracy: 0.9225\n",
      "Epoch 00027: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 25ms/step - loss: 0.2128 - accuracy: 0.9226 - val_loss: 0.5344 - val_accuracy: 0.8343\n",
      "Epoch 28/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.2104 - accuracy: 0.9277\n",
      "Epoch 00028: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 30ms/step - loss: 0.2098 - accuracy: 0.9278 - val_loss: 0.5331 - val_accuracy: 0.8295\n",
      "Epoch 29/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.2112 - accuracy: 0.9292\n",
      "Epoch 00029: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 27ms/step - loss: 0.2105 - accuracy: 0.9296 - val_loss: 0.5403 - val_accuracy: 0.8319\n",
      "Epoch 30/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.2014 - accuracy: 0.9317\n",
      "Epoch 00030: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 33ms/step - loss: 0.2009 - accuracy: 0.9318 - val_loss: 0.5532 - val_accuracy: 0.8343\n",
      "Epoch 31/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.1902 - accuracy: 0.9338 ETA: 0s - loss: 0\n",
      "Epoch 00031: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 30ms/step - loss: 0.1900 - accuracy: 0.9339 - val_loss: 0.5578 - val_accuracy: 0.8295\n",
      "Epoch 32/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1935 - accuracy: 0.9348\n",
      "Epoch 00032: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 26ms/step - loss: 0.1935 - accuracy: 0.9348 - val_loss: 0.5620 - val_accuracy: 0.8380\n",
      "Epoch 33/70\n",
      "101/103 [============================>.] - ETA: 0s - loss: 0.1891 - accuracy: 0.9347\n",
      "Epoch 00033: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 32ms/step - loss: 0.1874 - accuracy: 0.9354 - val_loss: 0.5734 - val_accuracy: 0.8319\n",
      "Epoch 34/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1863 - accuracy: 0.9403\n",
      "Epoch 00034: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 27ms/step - loss: 0.1863 - accuracy: 0.9403 - val_loss: 0.5804 - val_accuracy: 0.8210\n",
      "Epoch 35/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.1889 - accuracy: 0.9406\n",
      "Epoch 00035: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 30ms/step - loss: 0.1879 - accuracy: 0.9409 - val_loss: 0.5777 - val_accuracy: 0.8295\n",
      "Epoch 36/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1883 - accuracy: 0.9357\n",
      "Epoch 00036: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 4s 41ms/step - loss: 0.1883 - accuracy: 0.9357 - val_loss: 0.5728 - val_accuracy: 0.8222\n",
      "Epoch 37/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1805 - accuracy: 0.9418\n",
      "Epoch 00037: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 33ms/step - loss: 0.1805 - accuracy: 0.9418 - val_loss: 0.5777 - val_accuracy: 0.8270\n",
      "Epoch 38/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1724 - accuracy: 0.9415\n",
      "Epoch 00038: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 30ms/step - loss: 0.1724 - accuracy: 0.9415 - val_loss: 0.5854 - val_accuracy: 0.8258\n",
      "Epoch 39/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1776 - accuracy: 0.9394\n",
      "Epoch 00039: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 4s 35ms/step - loss: 0.1776 - accuracy: 0.9394 - val_loss: 0.5975 - val_accuracy: 0.8222\n",
      "Epoch 40/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1656 - accuracy: 0.9430\n",
      "Epoch 00040: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 4s 39ms/step - loss: 0.1656 - accuracy: 0.9430 - val_loss: 0.6006 - val_accuracy: 0.8307\n",
      "Epoch 41/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1679 - accuracy: 0.9443\n",
      "Epoch 00041: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 7s 63ms/step - loss: 0.1679 - accuracy: 0.9443 - val_loss: 0.6070 - val_accuracy: 0.8197\n",
      "Epoch 42/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1652 - accuracy: 0.9461\n",
      "Epoch 00042: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 7s 65ms/step - loss: 0.1652 - accuracy: 0.9461 - val_loss: 0.6037 - val_accuracy: 0.8307\n",
      "Epoch 43/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1633 - accuracy: 0.9443\n",
      "Epoch 00043: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 4s 41ms/step - loss: 0.1633 - accuracy: 0.9443 - val_loss: 0.6067 - val_accuracy: 0.8173\n",
      "Epoch 44/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1626 - accuracy: 0.9488\n",
      "Epoch 00044: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 6s 62ms/step - loss: 0.1626 - accuracy: 0.9488 - val_loss: 0.6130 - val_accuracy: 0.8173\n",
      "Epoch 45/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.1657 - accuracy: 0.9433\n",
      "Epoch 00045: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 32ms/step - loss: 0.1650 - accuracy: 0.9436 - val_loss: 0.6068 - val_accuracy: 0.8222\n",
      "Epoch 46/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.9473 ETA: 1s - loss: 0.1365  - ETA: 0s - loss: 0.143\n",
      "Epoch 00046: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 29ms/step - loss: 0.1540 - accuracy: 0.9473 - val_loss: 0.6132 - val_accuracy: 0.8161\n",
      "Epoch 47/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.1641 - accuracy: 0.9455\n",
      "Epoch 00047: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 31ms/step - loss: 0.1656 - accuracy: 0.9449 - val_loss: 0.6121 - val_accuracy: 0.8234\n",
      "Epoch 48/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.1557 - accuracy: 0.9449\n",
      "Epoch 00048: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 31ms/step - loss: 0.1558 - accuracy: 0.9449 - val_loss: 0.6326 - val_accuracy: 0.8173\n",
      "Epoch 49/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.1613 - accuracy: 0.9464\n",
      "Epoch 00049: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 31ms/step - loss: 0.1612 - accuracy: 0.9464 - val_loss: 0.6381 - val_accuracy: 0.8124\n",
      "Epoch 50/70\n",
      "101/103 [============================>.] - ETA: 0s - loss: 0.1510 - accuracy: 0.9505\n",
      "Epoch 00050: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 31ms/step - loss: 0.1517 - accuracy: 0.9504 - val_loss: 0.6425 - val_accuracy: 0.8270\n",
      "Epoch 51/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1566 - accuracy: 0.9497\n",
      "Epoch 00051: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 31ms/step - loss: 0.1566 - accuracy: 0.9497 - val_loss: 0.6421 - val_accuracy: 0.8112\n",
      "Epoch 52/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.1531 - accuracy: 0.9464\n",
      "Epoch 00052: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 30ms/step - loss: 0.1530 - accuracy: 0.9464 - val_loss: 0.6473 - val_accuracy: 0.8222\n",
      "Epoch 53/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.1483 - accuracy: 0.9458\n",
      "Epoch 00053: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 31ms/step - loss: 0.1498 - accuracy: 0.9452 - val_loss: 0.6384 - val_accuracy: 0.8124\n",
      "Epoch 54/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.1511 - accuracy: 0.9491\n",
      "Epoch 00054: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 30ms/step - loss: 0.1518 - accuracy: 0.9491 - val_loss: 0.6516 - val_accuracy: 0.8136\n",
      "Epoch 55/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.1495 - accuracy: 0.9485\n",
      "Epoch 00055: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 31ms/step - loss: 0.1493 - accuracy: 0.9485 - val_loss: 0.6440 - val_accuracy: 0.8246\n",
      "Epoch 56/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1406 - accuracy: 0.9513\n",
      "Epoch 00056: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 30ms/step - loss: 0.1406 - accuracy: 0.9513 - val_loss: 0.6543 - val_accuracy: 0.8124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.1451 - accuracy: 0.9513 ETA: 0s - loss:\n",
      "Epoch 00057: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 31ms/step - loss: 0.1445 - accuracy: 0.9516 - val_loss: 0.6481 - val_accuracy: 0.8197\n",
      "Epoch 58/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1432 - accuracy: 0.9519\n",
      "Epoch 00058: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 31ms/step - loss: 0.1432 - accuracy: 0.9519 - val_loss: 0.6559 - val_accuracy: 0.8088\n",
      "Epoch 59/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.1412 - accuracy: 0.9507\n",
      "Epoch 00059: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 31ms/step - loss: 0.1408 - accuracy: 0.9507 - val_loss: 0.6444 - val_accuracy: 0.8124\n",
      "Epoch 60/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1390 - accuracy: 0.9504 ETA: 0s - loss: 0.1394 - accura\n",
      "Epoch 00060: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 32ms/step - loss: 0.1390 - accuracy: 0.9504 - val_loss: 0.6637 - val_accuracy: 0.8185\n",
      "Epoch 61/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1337 - accuracy: 0.9528\n",
      "Epoch 00061: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 6s 57ms/step - loss: 0.1337 - accuracy: 0.9528 - val_loss: 0.6671 - val_accuracy: 0.8149\n",
      "Epoch 62/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1508 - accuracy: 0.9467\n",
      "Epoch 00062: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 7s 65ms/step - loss: 0.1508 - accuracy: 0.9467 - val_loss: 0.6650 - val_accuracy: 0.8027\n",
      "Epoch 63/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1419 - accuracy: 0.9500\n",
      "Epoch 00063: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 31ms/step - loss: 0.1419 - accuracy: 0.9500 - val_loss: 0.6601 - val_accuracy: 0.8197\n",
      "Epoch 64/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1356 - accuracy: 0.9516\n",
      "Epoch 00064: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 31ms/step - loss: 0.1356 - accuracy: 0.9516 - val_loss: 0.6882 - val_accuracy: 0.8100\n",
      "Epoch 65/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.1325 - accuracy: 0.9544\n",
      "Epoch 00065: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 32ms/step - loss: 0.1320 - accuracy: 0.9546 - val_loss: 0.6895 - val_accuracy: 0.8063\n",
      "Epoch 66/70\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.1343 - accuracy: 0.9525\n",
      "Epoch 00066: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 31ms/step - loss: 0.1336 - accuracy: 0.9528 - val_loss: 0.6861 - val_accuracy: 0.8076\n",
      "Epoch 67/70\n",
      "101/103 [============================>.] - ETA: 0s - loss: 0.1376 - accuracy: 0.9533\n",
      "Epoch 00067: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 3s 33ms/step - loss: 0.1375 - accuracy: 0.9531 - val_loss: 0.6772 - val_accuracy: 0.8185\n",
      "Epoch 68/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1277 - accuracy: 0.9537\n",
      "Epoch 00068: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 6s 63ms/step - loss: 0.1277 - accuracy: 0.9537 - val_loss: 0.7018 - val_accuracy: 0.8112\n",
      "Epoch 69/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.95 - ETA: 0s - loss: 0.1261 - accuracy: 0.9567\n",
      "Epoch 00069: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 7s 66ms/step - loss: 0.1261 - accuracy: 0.9567 - val_loss: 0.6852 - val_accuracy: 0.8161\n",
      "Epoch 70/70\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1291 - accuracy: 0.9546\n",
      "Epoch 00070: val_accuracy did not improve from 0.84044\n",
      "103/103 [==============================] - 7s 65ms/step - loss: 0.1291 - accuracy: 0.9546 - val_loss: 0.6870 - val_accuracy: 0.8002\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "model1 = Sequential()\n",
    "model1.add(layers.Embedding(max_words, 20)) #The embedding layer\n",
    "model1.add(layers.LSTM(15,dropout=0.5)) #Our LSTM layer\n",
    "model1.add(layers.Dense(3,activation='softmax'))\n",
    "\n",
    "\n",
    "model1.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpoint1 = ModelCheckpoint(\"best_model2.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
    "history = model1.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ad8e21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = keras.models.load_model(\"best_model2.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0ddf095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 - 2s - loss: 0.5194 - accuracy: 0.8404 - 2s/epoch - 73ms/step\n",
      "Model accuracy:  0.8404384851455688\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=2)\n",
    "print('Model accuracy: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e376c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b09c44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test.argmax(axis=1), np.around(predictions, decimals=0).argmax(axis=1))\n",
    "import seaborn as sns\n",
    "conf_matrix = pd.DataFrame(matrix, index = ['Neutral','Negative','Positive'],columns = ['Neutral','Negative','Positive'])\n",
    "#Normalizing\n",
    "conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure(figsize = (15,15))\n",
    "sns.heatmap(conf_matrix, annot=True, annot_kws={\"size\": 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1fa4664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new prediction\n",
    "sentiment = ['Neutral','Negative','Positive']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "59614308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = tokenizer.texts_to_sequences(['i love watching cricket'])\n",
    "test = pad_sequences(sequence, maxlen=max_len)\n",
    "sentiment[np.around(best_model.predict(test), decimals=0).argmax(axis=1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43a6b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
